{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - Non-negative Matrix Factorization\n",
    "The goal is to study the use of nonnegative matrix factorisation (NMF) for topic extraction from a dataset of text documents. The rationale is to interpret each extracted NMF component as being associated with a specific topic. \n",
    "\n",
    "Study and test the following script (introduced  on [scikit](http://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html))\n",
    "\n",
    "1. Test and comment on the effect of varying the initialisation, especially using random\n",
    "nonnegative values as initial guesses (for W and H coefficients, using the notations introduced\n",
    "during the lecture).\n",
    "2. Compare and comment on the difference between the results obtained with `2 cost compared\n",
    "to the generalised Kullback-Liebler cost.\n",
    "3. Test and comment on the results obtained using a simpler term-frequency representation\n",
    "as input (as opposed to the TF-IDF representation considered in the code above) when\n",
    "considering the Kullback-Liebler cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: 126.87913176003777\n",
      "Error on iteration 1: 83.05725059261255\n",
      "Error on iteration 2: 78.03751930502544\n",
      "Error on iteration 3: 75.73357179188885\n",
      "Error on iteration 4: 75.42456719235722\n",
      "Error on iteration 5: 75.27507869109539\n",
      "Error on iteration 6: 74.89451925327508\n",
      "Error on iteration 7: 74.58897173405492\n",
      "Error on iteration 8: 74.5004458586124\n",
      "Error on iteration 9: 74.59616319908983\n"
     ]
    }
   ],
   "source": [
    "###### CUSTOM NMF IMPLEMENTATION ######\n",
    "# Multiplicative Update Rules for NMF #\n",
    "# estimation with beta divergences    #\n",
    "import numpy\n",
    "\n",
    "# TODO: translate slides 59 [beta-divergence] & 47 [error and special cases]\n",
    "\n",
    "def custom_NMF(V, K, W=None, H=None, steps=50, beta=0, toll=0.1, show_div=False):\n",
    "    \n",
    "    F = len(V) #Number of V rows\n",
    "    N = len(V[0]) #Number of V columns\n",
    "\n",
    "    if W is None:\n",
    "        W = numpy.random.rand(F,K)\n",
    "        \n",
    "    if H is None:\n",
    "        H = numpy.random.rand(K,N)\n",
    "        \n",
    "    if N != len(H[0]):\n",
    "        raise ValueError(\"Size for H[0] is different - found \"+str(len(H[0]))+\" in place of \"+str(N))\n",
    "    if F != len(W):\n",
    "        raise ValueError(\"Size for F is different - found \"+str(len(F))+\" in place of \"+str(N))\n",
    "        \n",
    "    #Setup n_iter\n",
    "    n_iter = 1\n",
    "    \n",
    "    # Setup initial error\n",
    "    init_error = _beta_div(V,W,H,beta,F,N,K)\n",
    "    if show_div:\n",
    "        print(\"Initial error: \"+str(init_error))\n",
    "    error = init_error\n",
    "    \n",
    "    for step in range(steps):\n",
    "    \n",
    "#         Tests with whole matrix : multiply = O | dot = *\n",
    "        upd_UP = numpy.dot(W.T, numpy.multiply(pow(numpy.dot(W,H),beta-2), V))\n",
    "        upd_DOWN = numpy.dot(W.T, pow(numpy.dot(W,H),beta-1))\n",
    "        upd = upd_UP / upd_DOWN\n",
    "        H = numpy.multiply(H, upd)\n",
    "        \n",
    "        upd_UP = numpy.dot(numpy.multiply(pow(numpy.dot(W,H),beta-2), V),H.T)\n",
    "        upd_DOWN = numpy.dot(pow(numpy.dot(W,H),beta-1), H.T)\n",
    "        upd = upd_UP / upd_DOWN\n",
    "        W = numpy.multiply(W, upd)\n",
    "\n",
    "        # Test element-wise products\n",
    "#         for i in range(F):\n",
    "#             for j in range(N):\n",
    "#                 for k in range(K):\n",
    "#                     x = V[i][j]\n",
    "#                     w = W[i][k]\n",
    "#                     h = H[k][j]\n",
    "#                     y = w*h\n",
    "# #                     print(\"x:\"+str(x)+\" | w:\"+str(w)+\" | h:\"+str(h)+\" | y:\"+str(y))\n",
    "#                     # Update h\n",
    "#                     upd_up = w*(pow(y,beta-2)*x)\n",
    "#                     upd_down = w*pow(y,beta-1)\n",
    "#                     upd = upd_up/upd_down\n",
    "#                     h = h*upd\n",
    "#                     # Update w\n",
    "#                     upd_up = (pow(y,beta-2)*x)*h\n",
    "#                     upd_down = pow(y,beta-1)*h\n",
    "#                     upd = upd_up/upd_down\n",
    "#                     w = w*upd\n",
    "        \n",
    "        if toll > 0:\n",
    "            new_error = _beta_div(V,W,H,beta,F,N,K)\n",
    "            if show_div:\n",
    "                print(\"Error on iteration \"+str(n_iter)+\": \" +str(new_error))\n",
    "            # Check if approximation error relative decrease is below the desired threshold\n",
    "            if ((error - new_error) / init_error) < toll:\n",
    "                break\n",
    "            error = new_error\n",
    "            \n",
    "        n_iter += 1\n",
    "            \n",
    "    return W, H\n",
    "\n",
    "def _beta_div(V,W,H,beta,F,N,K):\n",
    "    div = 0\n",
    "    # Update beta_divergence\n",
    "    if beta == 1: # generalized Kullback-Leibler divergence. x log(x/y) - x + y\n",
    "        # div = numpy.dot(V, numpy.log(V,numpy.dot(W,H))) - numpy.sum(V) + numpy.sum(numpy.dot(W,H))\n",
    "        for i in range(F):\n",
    "            for j in range(N):\n",
    "                for k in range(K):\n",
    "                    x = V[i][j]\n",
    "                    y = W[i][k]*H[k][j]\n",
    "                    div += x*numpy.log(x/y) - x + y\n",
    "    elif beta == 0: # Itakura-Saito divergence. (x/y) - log(x/y) -1\n",
    "        # div = numpy.sum(V / numpy.dot(W,H)) - numpy.sum(numpy.log(V / numpy.dot(W,H))) - numpy.product(len(V))\n",
    "        for i in range(F):\n",
    "            for j in range(N):\n",
    "                for k in range(K):\n",
    "                    x = V[i][j]\n",
    "                    y = W[i][k]*H[k][j]\n",
    "                    div += (x/y) * numpy.log(x/y) - 1\n",
    "    else: # Euclidean distance. (1/beta(beta-1))(x^beta + (beta-1)y^beta - beta*x*y^beta-1)\n",
    "        left_factor = 1/(beta*(beta-1))\n",
    "        # div = left_factor*(pow(numpy.sum(V), beta) + (beta-1)*pow(numpy.sum(numpy.dot(W,H),beta)) - beta*numpy.sum(V)*pow(numpy.sum(numpy.dot(W,H),beta)))\n",
    "        for i in range(F):\n",
    "            for j in range(N):\n",
    "                for k in range(K):\n",
    "                    x = V[i][j]\n",
    "                    y = W[i][k]*H[k][j]\n",
    "                    div += left_factor*(pow(x,beta) + (beta-1)*pow(y,beta) - beta*x*pow(y,beta-1))\n",
    "    return div\n",
    "\n",
    "#######\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    V = [\n",
    "         [5,3,0,1],\n",
    "         [4,0,0,1],\n",
    "         [1,1,0,5],\n",
    "         [1,0,0,4],\n",
    "         [0,1,5,4],\n",
    "        ]\n",
    "\n",
    "    V = numpy.array(V) # Data matrix F x N \n",
    "    K = 2\n",
    "\n",
    "    W, H = custom_NMF(V, K, beta = 2, toll = 0.0001, show_div = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00404669, 1.11801199],\n",
       "       [0.00189289, 0.75267693],\n",
       "       [1.01006549, 0.39385685],\n",
       "       [0.77534413, 0.31250428],\n",
       "       [1.7904365 , 0.03975826]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### TEST RESULTS #####\n",
    "W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
