{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - Automatic Segmentation of Mails\n",
    "This Lab aims to build an email segmentation tool, dedicated to separate the email header from its\n",
    "body. It is proposed to perform this task by learning a HMM (A, B, π) with two states, one (*state 1*) for\n",
    "the header, the other (*state 2*) for the body. In this model, it is assumed that each mail actually contains\n",
    "a header : the decoding necessarily begins in the state 1.\n",
    "\n",
    "Knowing that each mail contains exactly one header and one body, each mail follows once the transition\n",
    "from 1 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 : Give the value of the π vector of the initial probabilities\n",
    "\n",
    "$$π^T = \n",
    "\\begin{matrix} \n",
    "1 \\\\ 0 \n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Because the initial probability of being in the state 0 (header) is always true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 : What is the probability to move from state 1 to state 2 ? What is the probability to remain in state 2 ? What is the lower/higher probability ? Try to explain why\n",
    "\n",
    "Given the matrix:\n",
    "\n",
    "$$ A = \\begin{matrix} \n",
    "0.999218078035812 & 0.000781921964187974 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}$$\n",
    "\n",
    "The probability of moving from state 1 to state 2 is `P(2|1) = 0.000781921964187974` ; the probability of state 2 is `P(2|2) = 1` . \n",
    "\n",
    "It is normal for P(2|2) to be higher, since once a character belonging to the *body* of the mail has been found, all the following observations will belong to the same state : no other *header* is found after the *body* in a mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 : What is the size of the corresponding matrix ?\n",
    "\n",
    "Because the ASCII characters are 256 (`N = 256`), the size of the corresponding matrix will be `256x2`, where each row represents the discrete probability distribution of the character *c* given the state *s*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementation of Viterbi algorithm\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Implementation of the Viterbi algorithm.\n",
    "Finds the best segmentation of the text provided, \n",
    "and returns the most probable states sequence\n",
    "Parameters explaination:\n",
    ":param O: = characters codification (ASCII, range(0,256))\n",
    ":param S: = possible states (header = 0, body = 1)\n",
    ":param A: = state transition probability matrix\n",
    ":param B: = matrix probability of character c being in state s (256x2, contained in P.text)\n",
    ":param pi: = initial probability vector\n",
    ":param Y: = observation in the mail (mail.dat)\n",
    ":return X: = most likely hidden state sequence\n",
    "\"\"\"\n",
    "def ViterbiAlgorithm(O, S, A, B, pi, Y):\n",
    "    A = np.matrix(A)\n",
    "    T = len(Y)\n",
    "    T1 = np.zeros((len(S), T))\n",
    "    T2 = np.zeros((len(S), T))\n",
    "    for s in S:\n",
    "        T1[s,0] = pi[s]*B[Y[0]][s] # vector of most likely path so far\n",
    "        T2[s,0] = 0 # most likely path for previous observation\n",
    "#     print(T1[:,0])\n",
    "    for t in range(1,T):\n",
    "        for s in S:\n",
    "#             print(\"T1[:,\"+str(t-1)+\"] = \"+str(T1[:,t-1]))\n",
    "#             print(\"A[:][s] = \"+str(A[:,s]))\n",
    "#             print(\"B[Y[\"+str(t)+\"],s] = \"+str(B[Y[t],s]))\n",
    "#             result = T1[:, t-1]*A[:,s]*B[Y[t],s]\n",
    "            result = [a*b*B[Y[t],s] for a,b in zip(T1[:, t-1],A[:,s])]\n",
    "            result += np.finfo(np.double).tiny\n",
    "#             print(\"Result = \"+str(result))\n",
    "            T1[s, t] = max(result)\n",
    "            T2[s, t] = np.argmax(result)\n",
    "#         print(T1[:,t])\n",
    "    Z = [0 for t in Y]\n",
    "    X = [0 for t in Y]\n",
    "    T = T - 1\n",
    "    Z[T] = int(np.argmax(T1[:,T]))\n",
    "    X[T] = S[Z[T]]\n",
    "    for i in range(T, 0, -1):\n",
    "        Z[i-1] = int(T2[Z[i], i])\n",
    "        X[i-1] = S[Z[i-1]]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 161, 3314])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viterbi - test\n",
    "O = range(0,256)\n",
    "S = [0,1]\n",
    "pi = [1,0]\n",
    "A = [[0.999218078035812, 0.000781921964187974],[0, 1]]\n",
    "B = np.loadtxt('P.text', dtype=float)\n",
    "Y = np.loadtxt('dat/mail11.dat',dtype=int)\n",
    "\n",
    "X = ViterbiAlgorithm(O, S, A, B, pi, Y)\n",
    "np.bincount(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 180, 4980])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.loadtxt('dat/mail30.dat',dtype=int)\n",
    "\n",
    "X = ViterbiAlgorithm(O, S, A, B, pi, Y)\n",
    "np.bincount(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
